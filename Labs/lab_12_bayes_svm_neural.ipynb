{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg4iowmJL2Sf"
      },
      "source": [
        "> ### Note on Labs and Assignments:\n",
        ">\n",
        "> üîß Look for the **wrench emoji** üîß ‚Äî it highlights where you're expected to take action!\n",
        ">\n",
        "> These sections are graded and are not optional.\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzjjuIUALoXZ"
      },
      "source": [
        "# IS 4487 Lab 12: Naive Bayes, SVM, and Neural Networks\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Apply Naive Bayes to a binary classification problem  \n",
        "- Train a Support Vector Machine (SVM) model  \n",
        "- Explore a simple Neural Network for classification  \n",
        "- Evaluate models using accuracy and classification reports  \n",
        "- Compare performance and discuss model selection  \n",
        "\n",
        "In this lab, we‚Äôll explore three advanced classification models ‚Äî **Naive Bayes**, **Support Vector Machines (SVM)**, and **Neural Networks** ‚Äî to predict **high engagement** in Super Bowl YouTube ads based on video metadata and features.\n",
        "\n",
        "We‚Äôll use the **Super Bowl Ads dataset** and continue developing your skills in selecting and evaluating machine learning models.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Labs/lab_12_bayes_svm_neural.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxngoVZiMGrf"
      },
      "source": [
        "## Data Description\n",
        "\n",
        "The dataset for this lab consists of **YouTube metadata and thematic features** of Super Bowl commercials, originally sourced from [TidyTuesday (March 2, 2021)](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-03-02/youtube.csv).\n",
        "\n",
        "Each row represents one Super Bowl ad, and the dataset includes both **video characteristics** and **performance metrics**, such as view counts and like counts.\n",
        "\n",
        "Below are key variables we'll work with:\n",
        "\n",
        "| Variable                 | Type        | Description                                                                 |\n",
        "|--------------------------|-------------|------------------------------------------------------------------------------|\n",
        "| `year`                   | numeric     | Year the ad aired during the Super Bowl                                     |\n",
        "| `brand`                  | categorical | Advertiser brand (e.g., Doritos, Budweiser)                                 |\n",
        "| `funny`                  | binary      | Indicates if the ad uses humor (1 = yes, 0 = no)                            |\n",
        "| `show_product_quickly`  | binary      | Product is shown early in the video (1 = yes)                               |\n",
        "| `patriotic`              | binary      | Includes patriotic content (1 = yes)                                        |\n",
        "| `celebrity`              | binary      | Features a celebrity (1 = yes)                                              |\n",
        "| `danger`                 | binary      | Involves danger or risk (1 = yes)                                           |\n",
        "| `animals`                | binary      | Includes animals (1 = yes)                                                  |\n",
        "| `use_sex`                | binary      | Includes sexual content or appeal (1 = yes)                                 |\n",
        "| `view_count`             | numeric     | Total number of YouTube views for the ad                                    |\n",
        "| `like_count`             | numeric     | Number of likes the ad received on YouTube                                  |\n",
        "| `dislike_count`          | numeric     | Number of dislikes                                                          |\n",
        "| `favorite_count`         | numeric     | Number of favorites (often unused in modern YouTube data)                   |\n",
        "| `comment_count`          | numeric     | Number of comments                                                          |\n",
        "| `high_engagement`        | binary      | Derived variable: 1 if `like_count` above median, 0 otherwise (our target)  |\n",
        "\n",
        "### Why this dataset?\n",
        "\n",
        "This dataset is perfect for:\n",
        "- **Classification tasks**: Predict whether an ad achieved high engagement.\n",
        "- **Marketing insights**: Identify which ad traits (e.g., humor, celebrities) drive viewer responses.\n",
        "- **Model interpretation**: Practice with models suited for both binary and numerical data.\n",
        "\n",
        "Throughout the lab, we'll focus on the `high_engagement` variable as the **target** and explore how ad content features relate to audience engagement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_g0i9hkMTBi"
      },
      "source": [
        "## Part 1: Load and Clean the Data\n",
        "\n",
        "In this first step, we will:\n",
        "- Load the dataset from GitHub url\n",
        "- Clean and preprocess it by removing irrelevant columns.\n",
        "- Engineer a binary target variable for \"high engagement\" (above median likes).\n",
        "\n",
        "This will ensure the data is in a format that can be used effectively for modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fccJdJAFIwVy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "url = 'https://raw.githubusercontent.com/Stan-Pugsley/is_4487_base/main/DataSets/youtube.csv'\n",
        "youtube = pd.read_csv(url)\n",
        "\n",
        "# Drop irrelevant or complex API columns\n",
        "youtube = youtube.drop(columns=[\n",
        "    'superbowl_ads_dot_com_url', 'youtube_url', 'id', 'kind', 'etag',\n",
        "    'published_at', 'title', 'description', 'thumbnail', 'channel_title'\n",
        "])\n",
        "\n",
        "# Convert logical (boolean) columns to integers for modeling\n",
        "logical_columns = ['funny', 'show_product_quickly', 'patriotic', 'celebrity', 'danger', 'animals', 'use_sex']\n",
        "youtube[logical_columns] = youtube[logical_columns].astype(int)\n",
        "\n",
        "# Drop rows with missing like_count\n",
        "youtube = youtube.dropna(subset=['like_count', 'view_count'])\n",
        "\n",
        "# Create target: high_engagement\n",
        "median_likes = youtube['like_count'].median()\n",
        "youtube['high_engagement'] = (youtube['like_count'] > median_likes).astype(int)\n",
        "\n",
        "\n",
        "# Final feature set\n",
        "youtube[['view_count', 'like_count', 'high_engagement'] + logical_columns].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYk0ijucMblE"
      },
      "source": [
        "## Part 2: Naive Bayes Classifier\n",
        "\n",
        "Naive Bayes is a **probabilistic model** based on Bayes' Theorem. It assumes **independence** between features, which isn't always true‚Äîbut it works surprisingly well for text and binary features.\n",
        "\n",
        "We'll use the boolean ad features (like `funny`, `celebrity`, etc.) to predict whether the video had high engagement.\n",
        "\n",
        "Ask Yourself:\n",
        "- Do you think any of these features (like \"celebrity\") might strongly influence likes?\n",
        "- How might the independence assumption affect the predictions?\n",
        "\n",
        "Let's train the model and evaluate performance using a **confusion matrix** and **classification report**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2puWt9tdMloI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Features and labels\n",
        "X = youtube[logical_columns]\n",
        "y = youtube['high_engagement']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "nb_model = BernoulliNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjFaYMDQMon8"
      },
      "source": [
        "### üîß Try It Yourself ‚Äî Part 2\n",
        "\n",
        "1. **Change the test size** to `0.2`. How does this affect accuracy?  \n",
        "   > Update `train_test_split(test_size=0.2)` and rerun the model.\n",
        "\n",
        "2. **Remove `celebrity` and `funny` features** from X. Rerun the model and check performance.  \n",
        "   > Modify:  \n",
        "   `X = youtube[['show_product_quickly', 'patriotic', 'danger', 'animals', 'use_sex']]`\n",
        "\n",
        "### In Your Response:\n",
        "\n",
        "1. Which model setup performed best? Why might that be?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vK-HTs0vFgn"
      },
      "outputs": [],
      "source": [
        "# üîß Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YczZyD_kvFVH"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Fds3ucNQBZ"
      },
      "source": [
        "## Part 3: Support Vector Machine (SVM)\n",
        "\n",
        "### What you're going to do:\n",
        "Use a **Support Vector Machine** with an RBF kernel to classify ads, using both binary and numeric features.\n",
        "\n",
        "### Why this matters:\n",
        "SVMs are powerful for high-dimensional data and can find optimal decision boundaries. They are also common in fraud detection and image recognition.\n",
        "\n",
        "### Regularization Parameter (C):\n",
        "\n",
        "- In the model parameters, you will see `C`, which controls the trade-off between achieving a low training error and a low testing error (generalization).\n",
        "\n",
        "- A large `C` value (e.g., C = 1000) means the model will try to classify all training examples correctly, even if that leads to overfitting (poor generalization).\n",
        "\n",
        "- A small `C` value (e.g., C = 0.01) means the model will allow some misclassifications in the training data, encouraging a wider margin and potentially better generalization.\n",
        "\n",
        "### What to notice:\n",
        "- How does scaling the data affect performance?\n",
        "- What happens when you change the kernel or regularization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPEmMcuQN3xv"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Add numeric feature\n",
        "X_full = youtube[logical_columns + ['view_count']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_full)\n",
        "\n",
        "# Split\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
        "svm_model.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = svm_model.predict(X_test_svm)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_svm))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_svm))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_svm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_QzP-f_N6kK"
      },
      "source": [
        "### üîß Try It Yourself ‚Äî Part 3\n",
        "\n",
        "1. **Change the kernel** to `'linear'` or `'poly'`.  \n",
        "2. **Try 2 different `C` values** like `0.1`, `1`, and `10`. Observe what changes. \n",
        "\n",
        "### In Your Response: \n",
        "1. What‚Äôs the tradeoff between higher and lower values of `C`?\n",
        "2. Which value of C gives you the maximum Accuracy?  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsK_zeHnN7iH"
      },
      "outputs": [],
      "source": [
        "# üîß Add code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyRxenDfN9HM"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU91G9xEOAZz"
      },
      "source": [
        "## Part 4: Neural Networks\n",
        "\n",
        "### What you're going to do:\n",
        "Build a basic **feedforward neural network** to classify ad engagement.\n",
        "\n",
        "### Why this matters:\n",
        "Neural networks are the foundation of modern AI. Even a simple one can outperform traditional models when tuned correctly.\n",
        "\n",
        "### What to notice:\n",
        "- This may take several minutes to run!  Be patient.\n",
        "- How does training accuracy compare to validation accuracy?\n",
        "- Do more layers or epochs help ‚Äî or hurt?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRtDeXbAOGkZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),  #Layer 1\n",
        "    Dense(8, activation='relu'),  #Layer 2\n",
        "    Dense(4, activation='relu'),  #Layer 3\n",
        "    Dense(1, activation='sigmoid') #Output Layer\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=20, batch_size=16, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tctKhkKpOIj2"
      },
      "outputs": [],
      "source": [
        "# Plot learning curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.title('Loss Over Time')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.title('Accuracy Over Time')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2Xwu2LNOTWM"
      },
      "source": [
        "### üîß Try It Yourself ‚Äî Part 4\n",
        "\n",
        "1. **Add or remove hidden layers** (e.g., try a single-layer model).\n",
        "2. **Increase batch size** to `32` or reduce it to `8`. Observe training time and performance.\n",
        "3. **Add `Dropout`** to your model\n",
        "\n",
        "### In Your Response:\n",
        "1. What is the optimial number of layers and batch size that you can find?  (you should try about 5 different combinations)\n",
        "2. Does adding `Dropout` help reduce overfitting? Use the loss plot to support your answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11lrJbJDOad-"
      },
      "outputs": [],
      "source": [
        "# üîß Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7FnRfAFOcd5"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9mvbHXCOeFt"
      },
      "source": [
        "## üîß Part 5: Reflection (100 words or less per question)\n",
        "\n",
        "1. Which model performed best on your dataset? Was it expected?\n",
        "2. Did any model appear to overfit or underfit? How could you tell?\n",
        "3. Which model would you recommend to a marketing team and why?\n",
        "\n",
        "You can use the accuracy scores, confusion matrices, and training graphs to support your conclusions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kx-ZDdpOisb"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. \n",
        "2. \n",
        "3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Your Notebook to Submit in Canvas\n",
        "- Use the instructions from Lab 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to html \"lab_12_LastnameFirstname.ipynb\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
