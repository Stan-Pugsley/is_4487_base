{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> # âš ï¸ **IMPORTANT: READ BEFORE STARTING THIS LAB**\n",
        ">\n",
        "> ### Throughout this lab, you will see **ðŸ”§ Try It Yourself** sections and a final ðŸ”§ **Reflection** section\n",
        ">\n",
        "> âœ… You are expected to:\n",
        "> - Complete each **\"ðŸ”§ Try It Yourselfâ€** section by writing and running your own code or answering the prompted questions in a markdown or python cell below the section.\n",
        "> - Answer the **Reflection** section at the end of the lab in your own words. This is your opportunity to summarize what you learned and connect the concepts.\n",
        "\n",
        ">\n",
        ">\n",
        "> ðŸ”§ Look for the **wrench emoji** ðŸ”§ â€” it highlights where you're expected to take action!\n",
        ">\n",
        "> ### These sections are **graded** and are **not optional**. Skipping them will impact your lab score.\n",
        ">\n",
        "> ---\n"
      ],
      "metadata": {
        "id": "Hg4iowmJL2Sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IS 4487 Lab 12: Naive Bayes, SVM, and Neural Networks\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Apply Naive Bayes to a binary classification problem  \n",
        "- Train a Support Vector Machine (SVM) model  \n",
        "- Explore a simple Neural Network for classification  \n",
        "- Evaluate models using accuracy and classification reports  \n",
        "- Compare performance and discuss model selection  \n",
        "\n",
        "In this lab, weâ€™ll explore three advanced classification models â€” **Naive Bayes**, **Support Vector Machines (SVM)**, and **Neural Networks** â€” to predict **high engagement** in Super Bowl YouTube ads based on video metadata and features.\n",
        "\n",
        "Weâ€™ll use the **Super Bowl Ads dataset** and continue developing your skills in selecting and evaluating machine learning models.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Labs/lab_12_bayes_svm_neural.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ],
      "metadata": {
        "id": "AzjjuIUALoXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Description\n",
        "\n",
        "The dataset for this lab consists of **YouTube metadata and thematic features** of Super Bowl commercials, originally sourced from [TidyTuesday (March 2, 2021)](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-03-02/youtube.csv).\n",
        "\n",
        "Each row represents one Super Bowl ad, and the dataset includes both **video characteristics** and **performance metrics**, such as view counts and like counts.\n",
        "\n",
        "Below are key variables we'll work with:\n",
        "\n",
        "| Variable                 | Type        | Description                                                                 |\n",
        "|--------------------------|-------------|------------------------------------------------------------------------------|\n",
        "| `year`                   | numeric     | Year the ad aired during the Super Bowl                                     |\n",
        "| `brand`                  | categorical | Advertiser brand (e.g., Doritos, Budweiser)                                 |\n",
        "| `funny`                  | binary      | Indicates if the ad uses humor (1 = yes, 0 = no)                            |\n",
        "| `show_product_quickly`  | binary      | Product is shown early in the video (1 = yes)                               |\n",
        "| `patriotic`              | binary      | Includes patriotic content (1 = yes)                                        |\n",
        "| `celebrity`              | binary      | Features a celebrity (1 = yes)                                              |\n",
        "| `danger`                 | binary      | Involves danger or risk (1 = yes)                                           |\n",
        "| `animals`                | binary      | Includes animals (1 = yes)                                                  |\n",
        "| `use_sex`                | binary      | Includes sexual content or appeal (1 = yes)                                 |\n",
        "| `view_count`             | numeric     | Total number of YouTube views for the ad                                    |\n",
        "| `like_count`             | numeric     | Number of likes the ad received on YouTube                                  |\n",
        "| `dislike_count`          | numeric     | Number of dislikes                                                          |\n",
        "| `favorite_count`         | numeric     | Number of favorites (often unused in modern YouTube data)                   |\n",
        "| `comment_count`          | numeric     | Number of comments                                                          |\n",
        "| `high_engagement`        | binary      | Derived variable: 1 if `like_count` above median, 0 otherwise (our target)  |\n",
        "\n",
        "### Why this dataset?\n",
        "\n",
        "This dataset is perfect for:\n",
        "- **Classification tasks**: Predict whether an ad achieved high engagement.\n",
        "- **Marketing insights**: Identify which ad traits (e.g., humor, celebrities) drive viewer responses.\n",
        "- **Model interpretation**: Practice with models suited for both binary and numerical data.\n",
        "\n",
        "Throughout the lab, we'll focus on the `high_engagement` variable as the **target** and explore how ad content features relate to audience engagement.\n"
      ],
      "metadata": {
        "id": "vxngoVZiMGrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Load and Clean the Data\n",
        "\n",
        "In this first step, we will:\n",
        "- Load the dataset from GitHub url\n",
        "- Clean and preprocess it by removing irrelevant columns.\n",
        "- Engineer a binary target variable for \"high engagement\" (above median likes).\n",
        "\n",
        "This will ensure the data is in a format that can be used effectively for modeling.\n"
      ],
      "metadata": {
        "id": "f_g0i9hkMTBi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fccJdJAFIwVy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "url = 'https://raw.githubusercontent.com/Stan-Pugsley/is_4487_base/main/DataSets/youtube.csv'\n",
        "youtube = pd.read_csv(url)\n",
        "\n",
        "# Drop irrelevant or complex API columns\n",
        "youtube = youtube.drop(columns=[\n",
        "    'superbowl_ads_dot_com_url', 'youtube_url', 'id', 'kind', 'etag',\n",
        "    'published_at', 'title', 'description', 'thumbnail', 'channel_title'\n",
        "])\n",
        "\n",
        "# Convert logical (boolean) columns to integers for modeling\n",
        "logical_columns = ['funny', 'show_product_quickly', 'patriotic', 'celebrity', 'danger', 'animals', 'use_sex']\n",
        "youtube[logical_columns] = youtube[logical_columns].astype(int)\n",
        "\n",
        "# Drop rows with missing like_count\n",
        "youtube = youtube.dropna(subset=['like_count', 'view_count'])\n",
        "\n",
        "# Create target: high_engagement\n",
        "median_likes = youtube['like_count'].median()\n",
        "youtube['high_engagement'] = (youtube['like_count'] > median_likes).astype(int)\n",
        "\n",
        "\n",
        "# Final feature set\n",
        "youtube[['view_count', 'like_count', 'high_engagement'] + logical_columns].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Naive Bayes Classifier\n",
        "\n",
        "Naive Bayes is a **probabilistic model** based on Bayes' Theorem. It assumes **independence** between features, which isn't always trueâ€”but it works surprisingly well for text and binary features.\n",
        "\n",
        "We'll use the boolean ad features (like `funny`, `celebrity`, etc.) to predict whether the video had high engagement.\n",
        "\n",
        "Ask Yourself:\n",
        "- Do you think any of these features (like \"celebrity\") might strongly influence likes?\n",
        "- How might the independence assumption affect the predictions?\n",
        "\n",
        "Let's train the model and evaluate performance using a **confusion matrix** and **classification report**.\n"
      ],
      "metadata": {
        "id": "HYk0ijucMblE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Features and labels\n",
        "X = youtube[logical_columns]\n",
        "y = youtube['high_engagement']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "nb_model = BernoulliNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
      ],
      "metadata": {
        "id": "2puWt9tdMloI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ”§ Try It Yourself â€” Part 2\n",
        "\n",
        "1. **Change the test size** to `0.2`. How does this affect accuracy?  \n",
        "   > Update `train_test_split(test_size=0.2)` and rerun the model.\n",
        "\n",
        "2. **Remove `celebrity` and `funny` features** from X. Rerun the model and check performance.  \n",
        "   > Modify:  \n",
        "   `X = youtube[['show_product_quickly', 'patriotic', 'danger', 'animals', 'use_sex']]`\n",
        "\n",
        "3. Which model setup performed best? Why might that be?\n"
      ],
      "metadata": {
        "id": "SjFaYMDQMon8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”§ Add code here"
      ],
      "metadata": {
        "id": "8vK-HTs0vFgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”§ Add comments here:"
      ],
      "metadata": {
        "id": "YczZyD_kvFVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Support Vector Machine (SVM)\n",
        "\n",
        "### What you're going to do:\n",
        "Use a **Support Vector Machine** with an RBF kernel to classify ads, using both binary and numeric features.\n",
        "\n",
        "### Why this matters:\n",
        "SVMs are powerful for high-dimensional data and can find optimal decision boundaries. They are also common in fraud detection and image recognition.\n",
        "\n",
        "### What to notice:\n",
        "- How does scaling the data affect performance?\n",
        "- What happens when you change the kernel or regularization?"
      ],
      "metadata": {
        "id": "x5Fds3ucNQBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Add numeric feature\n",
        "X_full = youtube[logical_columns + ['view_count']]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_full)\n",
        "\n",
        "# Split\n",
        "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train SVM\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
        "svm_model.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = svm_model.predict(X_test_svm)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_svm))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_svm))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_svm))\n"
      ],
      "metadata": {
        "id": "XPEmMcuQN3xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ”§ Try It Yourself â€” Part 3\n",
        "\n",
        "1. **Change the kernel** to `'linear'` or `'poly'`.  \n",
        "2. **Try 2 different `C` values** like `0.1`, `1`, and `10`. Observe what changes.  \n",
        "3. Whatâ€™s the tradeoff between higher and lower values of `C`?\n"
      ],
      "metadata": {
        "id": "M_QzP-f_N6kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”§ Add code here:"
      ],
      "metadata": {
        "id": "jsK_zeHnN7iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”§ Add comment here:"
      ],
      "metadata": {
        "id": "ZyRxenDfN9HM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Neural Networks\n",
        "\n",
        "### What you're going to do:\n",
        "Build a basic **feedforward neural network** to classify ad engagement.\n",
        "\n",
        "### Why this matters:\n",
        "Neural networks are the foundation of modern AI. Even a simple one can outperform traditional models when tuned correctly.\n",
        "\n",
        "### What to notice:\n",
        "- How does training accuracy compare to validation accuracy?\n",
        "- Do more layers or epochs help â€” or hurt?\n"
      ],
      "metadata": {
        "id": "VU91G9xEOAZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train_svm.shape[1],)),\n",
        "    Dropout(0.2),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(4, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_svm, y_train_svm, validation_data=(X_test_svm, y_test_svm),\n",
        "                    epochs=60, batch_size=16, verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nn = (model.predict(X_test_svm) > 0.5).astype(int)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_svm, y_pred_nn))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nn))\n",
        "print(\"Accuracy:\", accuracy_score(y_test_svm, y_pred_nn))\n"
      ],
      "metadata": {
        "id": "SRtDeXbAOGkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss Over Time')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('Accuracy Over Time')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tctKhkKpOIj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ”§ Try It Yourself â€” Part 4\n",
        "\n",
        "1. **Add or remove hidden layers** (e.g., try a single-layer model).\n",
        "2. **Increase batch size** to `32` or reduce it to `8`. Observe training time and performance.\n",
        "3. Does adding `Dropout` help reduce overfitting? Use the loss plot to support your answer.\n"
      ],
      "metadata": {
        "id": "m2Xwu2LNOTWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”§ Add code here"
      ],
      "metadata": {
        "id": "11lrJbJDOad-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add comment here:"
      ],
      "metadata": {
        "id": "v7FnRfAFOcd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”§ Part 5: Reflection (100 words or less per question)\n",
        "\n",
        "1. Which model performed best on your dataset? Was it expected?\n",
        "2. Did any model appear to overfit or underfit? How could you tell?\n",
        "3. Which model would you recommend to a marketing team and why?\n",
        "\n",
        "You can use the accuracy scores, confusion matrices, and training graphs to support your conclusions.\n"
      ],
      "metadata": {
        "id": "q9mvbHXCOeFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”§ Add comment here"
      ],
      "metadata": {
        "id": "9kx-ZDdpOisb"
      }
    }
  ]
}
