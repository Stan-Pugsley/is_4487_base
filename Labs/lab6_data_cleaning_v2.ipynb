{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> # ⚠️ **IMPORTANT: READ BEFORE STARTING THIS LAB**\n",
        ">\n",
        "> ### Throughout this lab, you will see **🔧 Try It Yourself** sections and a final 🔧 **Reflection** section\n",
        ">\n",
        "> ✅ You are expected to:\n",
        "> - Complete each **\"🔧 Try It Yourself”** section by writing and running your own code or answering the prompted questions in a markdown or python cell below the section.\n",
        "> - Answer the **Reflection** section at the end of the lab in your own words. This is your opportunity to summarize what you learned and connect the concepts.\n",
        "\n",
        ">\n",
        ">\n",
        "> 🔧 Look for the **wrench emoji** 🔧 — it highlights where you're expected to take action!\n",
        ">\n",
        "> ### These sections are **graded** and are **not optional**. Skipping them will impact your lab score.\n",
        ">\n",
        "> ---"
      ],
      "metadata": {
        "id": "bSMMBBjMUKCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IS 4487 Lab 6: Data Cleaning\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Load and inspect a new dataset (Megatelco)\n",
        "- Fix column names and data types\n",
        "- Handle missing values\n",
        "- Remove duplicate rows\n",
        "- Review and remove outliers\n",
        "- Reflect on data quality\n",
        "\n",
        "In this lab, we’ll clean the data to get it ready for transformations and analysis.\n",
        "\n",
        "We will continue working with this dataset in **Lab 7**, where we will create new features and apply transformations.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Labs/lab6_data_cleaning_v2.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "wILWVHB_hdS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Megatelco Data Dictionary\n",
        "\n",
        " DEMOGRAPHIC VARIABLES:\n",
        " - College - has the customer attended some college (one, zero)\n",
        " - Income - annual income of customer\n",
        " - House - estimated price of the customer's home (if applicable)\n",
        "\n",
        " USAGE VARIABLES:\n",
        " - Data Overage Mb - Average number of megabytes that the customer used in excess of the plan limit (over last 12 months)\n",
        " - Data Leftover Mb - Average number of megabytes that the customer use was below the plan limit (over last 12 months)\n",
        " - Data Mb Used - Average number of megabytes used per month (over last 12 months)\n",
        " - Text Message Count - Average number of texts per month (over last 12 months)\n",
        " - Over 15 Minute Calls Per Month - Average number of calls over 15 minutes in duration per month (over last 12 months)\n",
        " - Average Call Duration- Average call duration (over last 12 months)\n",
        "\n",
        "PHONE VARIABLES:\n",
        " - Operating System - Current operating system of phone\n",
        " - Handset Price - Retail price of the phone used by the customer\n",
        "\n",
        "ATTITUDINAL VARIABLES:\n",
        " - Reported Satisfaction - Survey response to \"How satisfied are you with your current phone plan?\" (high, med, low)\n",
        " - Reported Usage Level - Survey response to \"How much do your use your phone?\" (high, med, low)\n",
        " - Considering Change of Plan - Survey response to \"Are you currently planning to change companies when your contract expires?\" (high, med, low)\n",
        "\n",
        "OTHER VARIABLES\n",
        " - Leave - Did this customer churn with the last contract expiration? (LEAVE, STAY)\n",
        " - ID - Customer identifier"
      ],
      "metadata": {
        "id": "7sL7v5VBhn0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Stan-Pugsley/is_4487_base/812e9f15c357a5657a2795631fcaa9d9363cb417/DataSets/megatelco_leave_survey_data_cleaning_v2.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()\n",
        "\n",
        "# create a copy of your dataset for use in part 4\n",
        "copied_df = df.copy(deep=True)\n"
      ],
      "metadata": {
        "id": "j7lmvMVURvit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Review Column Names and Structure\n",
        "\n",
        "Before cleaning, check the structure of the dataset:\n",
        "\n",
        "- Are column names consistent (lowercase, no spaces)?\n",
        "- Are there any typos or redundant labels?\n",
        "- Do the rows and columns appear aligned?\n",
        "\n",
        "Why this matters:\n",
        "Inconsistent or messy column names can break code and make analysis harder to follow.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x5EdJF_oiJDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize column names: lowercase, no spaces\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "# Get column info and data types\n",
        "df.info()"
      ],
      "metadata": {
        "id": "nm4Pnq-ViH38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Convert Data Types\n",
        "\n",
        "Before analysis, make sure each column is stored in the correct format. This helps avoid calculation errors, makes plotting smoother, and ensures models interpret the data correctly.\n",
        "\n",
        "Think about:\n",
        "- Are numbers accidentally stored as strings?\n",
        "- Should repeated text values be converted to categories?\n",
        "- Are \"yes\"/\"no\" columns better represented as binary (0/1) or categorical types?\n",
        "\n",
        "Fixing data types now saves time and avoids issues later in your workflow.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rRc0L4FGiYOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R4guI7lfgGi"
      },
      "outputs": [],
      "source": [
        "# Check original data types\n",
        "print(\"Original dtypes:\\n\", df.dtypes)\n",
        "\n",
        "# Convert yes/no to binary categories\n",
        "df['considering_change_of_plan'] = df['considering_change_of_plan'].map({'yes': 1, 'no': 0}).astype('category')\n",
        "\n",
        "# Convert categorical text columns\n",
        "df['college'] = df['college'].astype('category')\n",
        "df['house'] = df['house'].astype('category')\n",
        "df['reported_satisfaction'] = df['reported_satisfaction'].astype('category')\n",
        "df['operating_system'] = df['operating_system'].astype('category')\n",
        "\n",
        "# Convert numeric-looking columns from object to float\n",
        "df['income'] = pd.to_numeric(df['income'], errors='coerce')\n",
        "df['data_overage_mb'] = pd.to_numeric(df['data_overage_mb'], errors='coerce')\n",
        "df['data_leftover_mb'] = pd.to_numeric(df['data_leftover_mb'], errors='coerce')\n",
        "df['data_mb_used'] = pd.to_numeric(df['data_mb_used'], errors='coerce')\n",
        "df['text_message_count'] = pd.to_numeric(df['text_message_count'], errors='coerce')\n",
        "df['over_15mins_calls_per_month'] = pd.to_numeric(df['over_15mins_calls_per_month'], errors='coerce')\n",
        "df['average_call_duration'] = pd.to_numeric(df['average_call_duration'], errors='coerce')\n",
        "\n",
        "# Check updated data types\n",
        "print(\"\\nUpdated dtypes:\\n\", df.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔧 Try It Yourself – Part 2\n",
        "\n",
        "1. Convert the `leave` column from \"yes\"/\"no\" to binary (`1`/`0`) and make it a **category**\n",
        "2. Convert `reported_usage_level` to a **categorical** type\n",
        "3. Use `.astype()` and `.info()` to confirm the changes\n"
      ],
      "metadata": {
        "id": "C8diAR0Vil7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add code here 🔧"
      ],
      "metadata": {
        "id": "TxDe-Td1ilji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Handle Missing Values\n",
        "\n",
        "Missing data can break charts, skew stats, and disrupt models — so it needs to be handled carefully.\n",
        "\n",
        "### Think about:\n",
        "- Are the missing values random or patterned?\n",
        "- Can we drop rows, or do we need to fill them?\n",
        "- Should we use mean, median, or something else?\n",
        "\n",
        "### Guidelines:\n",
        "- Drop rows only if few are missing and the column is essential.\n",
        "- Use **median** for numeric columns with outliers.\n",
        "- Use **0** if missing logically means \"none\" (e.g., no leftover data).\n",
        "- Use **mode** for categorical values.\n",
        "\n",
        "Cleaning missing values early avoids bigger problems later.\n",
        "\n",
        "-----\n",
        "\n",
        "\n",
        "### A Note on `.loc` and Warnings\n",
        "\n",
        "When assigning values to a DataFrame, especially after filtering or copying, it's best to use `.loc` to avoid **`SettingWithCopyWarning`**. This ensures that you're updating the original data and not a temporary view of it.\n"
      ],
      "metadata": {
        "id": "V89jBNxwiqLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View missing value counts\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill 'handset_price' with median\n",
        "df['handset_price'] = df['handset_price'].fillna(df['handset_price'].median())\n",
        "\n",
        "# Drop rows with missing 'income' (if very few)\n",
        "df = df.dropna(subset=['income']).copy()\n",
        "\n",
        "# Fill missing 'data_leftover_mb' with 0 if it logically means no leftover data\n",
        "df.loc[:, 'data_leftover_mb'] = df['data_leftover_mb'].fillna(0)\n",
        "\n",
        "# Fill 'average_call_duration' with median if necessary\n",
        "df.loc[:, 'average_call_duration'] = df['average_call_duration'].fillna(df['average_call_duration'].median())\n",
        "\n",
        "# Fill 'data_mb_used' with median\n",
        "df.loc[:, 'data_mb_used'] = df['data_mb_used'].fillna(df['data_mb_used'].median())\n",
        "\n",
        "# Confirm updated missing values\n",
        "print(\"\\nMissing values after handling:\\n\", df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "_5CvIibPiwkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔧 Try It Yourself – Part 3\n",
        "\n",
        "\n",
        "There are still some missing values in:\n",
        "\n",
        "- `over_15mins_calls_per_month`\n",
        "- `considering_change_of_plan`\n",
        "\n",
        "Decide how to handle them based on what makes the most sense:\n",
        "\n",
        "- Should you fill them with 0, the median, or something else?\n",
        "- For categories, would a placeholder like \"unknown\" or the most common value work?\n",
        "- Or is it better to drop those rows?\n",
        "\n",
        "1. Write and execute code to handle the missing values in the remaining two columns.\n",
        "2. Use `df.isnull().sum()` to confirm all missing values are handled.\n",
        "\n"
      ],
      "metadata": {
        "id": "uYVOlmerk5_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add code here 🔧"
      ],
      "metadata": {
        "id": "yTFPZdink5Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Remove Duplicate Rows\n",
        "\n",
        "Sometimes the same row appears more than once due to data entry or processing mistakes. It's important to check for and remove these duplicates.\n",
        "\n",
        "Think about:\n",
        "- Are there rows that are exactly the same?\n",
        "- If duplicates exist, should you keep the first one, the last one, or none?\n",
        "\n",
        "Why this matters:\n",
        "Duplicate rows can inflate totals, distort statistics, and lead to inaccurate conclusions.\n"
      ],
      "metadata": {
        "id": "wGSRC2UsTipt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for exact duplicates\n",
        "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
        "\n",
        "# Remove them, keeping the first occurrence\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Confirm result\n",
        "print(f\"Remaining rows after removing duplicates: {len(df)}\")"
      ],
      "metadata": {
        "id": "1TOElN0LTmZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔧 Try It Yourself – Part 4\n",
        "\n",
        "1. Use `copied_df.duplicated().sum()` to count how many duplicates are in your dataset.\n",
        "2. Try using `copied_df.drop_duplicates(keep='last')` instead — what changes?\n",
        "3. Explore whether duplicate rows share the same ID or just values across all columns and comment on your observation.\n"
      ],
      "metadata": {
        "id": "iL3PCXy2Tl4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔧 Add code here:"
      ],
      "metadata": {
        "id": "UyFVNN7fTtWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔧 Add comment here:"
      ],
      "metadata": {
        "id": "-CJNfob8qeGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Identify and Remove Obvious Outliers\n",
        "\n",
        "Outliers are values that fall far outside the normal range. They can come from data entry mistakes or rare cases.\n",
        "\n",
        "- Use summary statistics or visual tools (like boxplots) to find them.\n",
        "- Look for clearly unrealistic values — e.g., negative prices or extremely high data usage.\n",
        "- Decide how to handle them:\n",
        "  - Remove if they’re errors.\n",
        "  - Keep if they’re valid but rare — or cap them if needed.\n",
        "\n",
        "Outliers can distort averages, stretch visualizations, and mislead models, so it’s important to address them carefully.\n",
        "\n"
      ],
      "metadata": {
        "id": "IrGThmZxTsdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove negative or nonsensical values using business rules\n",
        "\n",
        "# Example: remove rows where 'handset_price' is negative\n",
        "df = df[df['handset_price'] >= 0]\n",
        "\n",
        "# Example: remove rows with unusually long call durations\n",
        "df = df[df['average_call_duration'] < 1000]\n",
        "\n",
        "# Example: remove rows with extremely high text message counts\n",
        "df = df[df['text_message_count'] < 1000]\n",
        "\n",
        "# View shape after outlier filtering\n",
        "print(\"Shape after removing obvious outliers:\", df.shape)\n"
      ],
      "metadata": {
        "id": "yQkgPvH-TyV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔧 Try It Yourself – Part 5\n",
        "\n",
        "1. Use `df.describe()` to look for columns with extreme minimum or maximum values.\n",
        "2. Set a threshold for what you think is \"too high\" for:\n",
        "  - `data_mb_used`\n",
        "  - `over_15mins_calls_per_month`\n",
        "3. Remove those outliers using boolean filtering like `df = df[df['column'] < threshold]`"
      ],
      "metadata": {
        "id": "hs44Te_xT1x0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔧 add code here:"
      ],
      "metadata": {
        "id": "GZht29q2U_qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Handle Outliers Using Quantiles\n",
        "\n",
        "Instead of removing outliers, we can limit their impact by capping extreme values — a method known as **Winsorizing**.\n",
        "\n",
        "### How to Do It:\n",
        "- Use `.quantile()` to identify the 1st and 99th percentiles (or other thresholds).\n",
        "- Use `.clip()` to cap values within that range.\n",
        "\n",
        "This keeps your dataset intact while reducing the influence of extreme values on your analysis or model.\n",
        "\n"
      ],
      "metadata": {
        "id": "SDo8Cbb5T5ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate 1st and 99th percentiles for income\n",
        "income_min, income_max = df['income'].quantile([0.01, 0.99])\n",
        "\n",
        "# Use .loc to avoid SettingWithCopyWarning and ensure assignment modifies the original DataFrame\n",
        "df.loc[:, 'income'] = df['income'].clip(lower=income_min, upper=income_max)\n",
        "\n",
        "# Clip 'data_mb_used' to within 1st and 99th percentiles\n",
        "usage_min, usage_max = df['data_mb_used'].quantile([0.01, 0.99])\n",
        "df.loc[:, 'data_mb_used'] = df['data_mb_used'].clip(lower=usage_min, upper=usage_max)\n",
        "\n",
        "# Clip 'average_call_duration' to reduce the effect of extreme outliers\n",
        "call_min, call_max = df['average_call_duration'].quantile([0.01, 0.99])\n",
        "df.loc[:, 'average_call_duration'] = df['average_call_duration'].clip(lower=call_min, upper=call_max)\n",
        "\n"
      ],
      "metadata": {
        "id": "5MsTpfh1T-MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔧 Try It Yourself – Part 6\n",
        "\n",
        "1. Use `.quantile([0.01, 0.99])` to find the range for:\n",
        "  - `text_message_count`\n",
        "  - `over_15mins_calls_per_month`\n",
        "2. Apply `.clip(lower=..., upper=...)` to reduce the impact of those outliers\n",
        "3. Compare the `.describe()` output before and after clipping and comment on what you observe\n"
      ],
      "metadata": {
        "id": "Kl2KH2laUPhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔧 Add code here"
      ],
      "metadata": {
        "id": "zddKz_siUTXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔧 Add comment here:"
      ],
      "metadata": {
        "id": "rwiYJnFnrNLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔧 Part 7: Reflection (100 words or less per question)\n",
        "\n",
        "1. Which step fixed the most issues in the dataset?\n",
        "2. What surprised you about the structure or values?\n",
        "3. Do you feel this data is now ready for transformation in Lab 7?\n"
      ],
      "metadata": {
        "id": "FpSGvaBmT_9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "🔧 **Add comment here:**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "srnE_g7zULEm"
      }
    }
  ]
}