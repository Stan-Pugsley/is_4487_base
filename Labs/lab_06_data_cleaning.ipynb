{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSMMBBjMUKCW"
      },
      "source": [
        "> ### Note on Labs and Assignments:\n",
        ">\n",
        "> ðŸ”§ Look for the **wrench emoji** ðŸ”§ â€” it highlights where you're expected to take action!\n",
        ">\n",
        "> These sections are graded and are not optional.\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wILWVHB_hdS9"
      },
      "source": [
        "# IS 4487 Lab 6: Data Cleaning\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Load and inspect a new dataset (Megatelco)\n",
        "- Fix column names and data types\n",
        "- Handle missing values\n",
        "- Remove duplicate rows\n",
        "- Review and remove outliers\n",
        "- Reflect on data quality\n",
        "\n",
        "In this lab, weâ€™ll clean the data to get it ready for transformations and analysis.\n",
        "\n",
        "We will continue working with this dataset in **Lab 7**, where we will create new features and apply transformations.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Labs/lab_06_data_cleaning.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sL7v5VBhn0W"
      },
      "source": [
        "## Megatelco Data Dictionary\n",
        "\n",
        " DEMOGRAPHIC VARIABLES:\n",
        " - College - has the customer attended some college (one, zero)\n",
        " - Income - annual income of customer\n",
        " - House - estimated price of the customer's home (if applicable)\n",
        "\n",
        " USAGE VARIABLES:\n",
        " - Data Overage Mb - Average number of megabytes that the customer used in excess of the plan limit (over last 12 months)\n",
        " - Data Leftover Mb - Average number of megabytes that the customer use was below the plan limit (over last 12 months)\n",
        " - Data Mb Used - Average number of megabytes used per month (over last 12 months)\n",
        " - Text Message Count - Average number of texts per month (over last 12 months)\n",
        " - Over 15 Minute Calls Per Month - Average number of calls over 15 minutes in duration per month (over last 12 months)\n",
        " - Average Call Duration- Average call duration (over last 12 months)\n",
        "\n",
        "PHONE VARIABLES:\n",
        " - Operating System - Current operating system of phone\n",
        " - Handset Price - Retail price of the phone used by the customer\n",
        "\n",
        "ATTITUDINAL VARIABLES:\n",
        " - Reported Satisfaction - Survey response to \"How satisfied are you with your current phone plan?\" (high, med, low)\n",
        " - Reported Usage Level - Survey response to \"How much do you use your phone?\" (high, med, low)\n",
        " - Considering Change of Plan - Survey response to \"Are you currently planning to change companies when your contract expires?\" (high, med, low)\n",
        "\n",
        "OTHER VARIABLES\n",
        " - Leave - Did this customer churn with the last contract expiration? (LEAVE, STAY)\n",
        " - ID - Customer identifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7lmvMVURvit"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Stan-Pugsley/is_4487_base/812e9f15c357a5657a2795631fcaa9d9363cb417/DataSets/megatelco_leave_survey_data_cleaning_v2.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a copy of your dataset for use in part 4\n",
        "copied_df = df.copy(deep=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5EdJF_oiJDb"
      },
      "source": [
        "## Part 1: Review Column Names and Structure\n",
        "\n",
        "Before cleaning, check the structure of the dataset:\n",
        "\n",
        "- Are column names consistent (lowercase, no spaces)?\n",
        "- Are there any typos or redundant labels?\n",
        "- Do the rows and columns appear aligned? (Are all the columns the same size? Are all the rows the same size?)\n",
        "\n",
        "Why this matters:\n",
        "Inconsistent or messy column names can break code and make analysis harder to follow.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm4Pnq-ViH38"
      },
      "outputs": [],
      "source": [
        "# Standardize column names: lowercase, no spaces\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "# Get column info and data types\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRc0L4FGiYOz"
      },
      "source": [
        "## Part 2: Convert Data Types\n",
        "\n",
        "Before analysis, make sure each column is stored in the correct format. This helps avoid calculation errors, makes plotting smoother, and ensures models interpret the data correctly.\n",
        "\n",
        "Think about:\n",
        "- Are numbers accidentally stored as strings?\n",
        "- Should repeated text values be converted to categories?\n",
        "- Are \"yes\"/\"no\" columns better represented as binary (0/1) or categorical types?\n",
        "\n",
        "Fixing data types now saves time and avoids issues later in your workflow.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R4guI7lfgGi"
      },
      "outputs": [],
      "source": [
        "# Check original data types\n",
        "print(\"Original dtypes:\\n\", df.dtypes)\n",
        "\n",
        "# Convert categorical text columns\n",
        "df['college'] = df['college'].astype('category')\n",
        "df['reported_satisfaction'] = df['reported_satisfaction'].astype('category')\n",
        "df['operating_system'] = df['operating_system'].astype('category')\n",
        "\n",
        "# Convert object to nomimal categorical - can use df[colname].astype() to convert to nominal categorical\n",
        "obj_to_nomcat_cols = ['considering_change_of_plan', 'college', 'operating_system', 'leave']\n",
        "for acol in obj_to_nomcat_cols:\n",
        "    df[acol] = df[acol].astype('category')\n",
        "\n",
        "# Convert object/text columns with limited possible values with an order to ordinal categorical columns\n",
        "df['reported_satisfaction'] = pd.Categorical(df['reported_satisfaction'], categories = ['Low', 'Medium', 'High'], ordered = True)\n",
        "df['reported_usage_level'] = pd.Categorical(df['reported_usage_level'], categories = ['Low', 'Medium', 'High'], ordered = True)\n",
        "\n",
        "# Convert binary columns ('yes'/'no', 'LEAVE'/'STAY') to binary categorical\n",
        "df['considering_change_of_plan'] = df['considering_change_of_plan'].astype('category')\n",
        "df['leave'] = df['leave'].astype('category')  \n",
        "\n",
        "# Check updated data types\n",
        "print(\"\\nUpdated dtypes:\\n\", df.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8diAR0Vil7a"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€“ Part 2\n",
        "\n",
        "1. Convert the `leave` column from \"yes\"/\"no\" to binary (`1`/`0`) and make it a **category**\n",
        "2. Convert `reported_usage_level` to a **categorical** type\n",
        "3. Convert `house` to an **integer** type\n",
        "3. Use `.info()` to confirm the changes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxDe-Td1ilji"
      },
      "outputs": [],
      "source": [
        "# add code here ðŸ”§"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V89jBNxwiqLR"
      },
      "source": [
        "## Part 3: Handle Missing Values\n",
        "\n",
        "Missing data can break charts, skew stats, and disrupt models â€” so it needs to be handled carefully.\n",
        "\n",
        "### Think about:\n",
        "- Are the missing values random or patterned?\n",
        "- Can we drop rows, or do we need to fill them?\n",
        "- Should we use mean, median, or something else?\n",
        "\n",
        "### Guidelines:\n",
        "- Drop rows if there are only a few missing and the columns associated with them are essential to keep intact\n",
        "- Use median to replace outliers in numeric columns \n",
        "- Use 0 if the missing value means â€œnoneâ€ (e.g. If the value was in response to: â€œdo you have a history of chronic illness?â€ and the value was just left blank, we can assume that that blank just means â€œnoneâ€ (the patient has no history of chronic illness)) \n",
        "- Use mode to replace categorical values\n",
        "\n",
        "Cleaning missing values early avoids bigger problems later.\n",
        "\n",
        "-----\n",
        "\n",
        "\n",
        "**Note on `.loc` and Warnings** - When assigning values to a DataFrame, especially after filtering or copying, it's best to use `.loc` to avoid **`SettingWithCopyWarning`**. This ensures that you're updating the original data and not a temporary view of it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5CvIibPiwkZ"
      },
      "outputs": [],
      "source": [
        "# View missing value counts\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill 'handset_price' with median\n",
        "df['handset_price'] = df['handset_price'].fillna(df['handset_price'].median())\n",
        "\n",
        "# Drop rows with missing 'income' (if very few)\n",
        "df = df.dropna(subset=['income']).copy()\n",
        "\n",
        "# Fill missing 'data_leftover_mb' with 0 if it logically means no leftover data\n",
        "df.loc[:, 'data_leftover_mb'] = df['data_leftover_mb'].fillna(0)\n",
        "\n",
        "# Fill 'average_call_duration' with median if necessary\n",
        "df.loc[:, 'average_call_duration'] = df['average_call_duration'].fillna(df['average_call_duration'].median())\n",
        "\n",
        "# Fill 'data_mb_used' with median\n",
        "df.loc[:, 'data_mb_used'] = df['data_mb_used'].fillna(df['data_mb_used'].median())\n",
        "\n",
        "# Confirm updated missing values\n",
        "print(\"\\nMissing values after handling:\\n\", df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYVOlmerk5_2"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€“ Part 3\n",
        "\n",
        "\n",
        "There are still some missing values in:\n",
        "\n",
        "- `over_15mins_calls_per_month`\n",
        "- `considering_change_of_plan`\n",
        "\n",
        "Decide how to handle them based on what makes the most sense:\n",
        "\n",
        "- Should you fill them with 0, the median, or something else?\n",
        "- For categories, would a placeholder like \"unknown\" or the most common value work?\n",
        "- Or is it better to drop those rows?\n",
        "\n",
        "1. Write and execute code to handle the missing values in the remaining two columns.\n",
        "2. Use `df.isnull().sum()` to confirm all missing values are handled.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTFPZdink5Ua"
      },
      "outputs": [],
      "source": [
        "# Add code here ðŸ”§"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGSRC2UsTipt"
      },
      "source": [
        "## Part 4: Remove Duplicate Rows\n",
        "\n",
        "Sometimes the same row appears more than once due to data entry or processing mistakes. It's important to check for and remove these duplicates.\n",
        "\n",
        "Think about:\n",
        "- Are there rows that are exactly the same?\n",
        "- If duplicates exist, should you keep the first one, the last one, or none?\n",
        "\n",
        "Why this matters:\n",
        "Duplicate rows can inflate totals, distort statistics, and lead to inaccurate conclusions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TOElN0LTmZD"
      },
      "outputs": [],
      "source": [
        "# Check for exact duplicates\n",
        "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
        "\n",
        "# Remove them, keeping the first occurrence\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Confirm result\n",
        "print(f\"Remaining rows after removing duplicates: {len(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL3PCXy2Tl4z"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€“ Part 4\n",
        "\n",
        "1. Use `copied_df.duplicated().sum()` to count how many duplicates are in your dataset.\n",
        "2. Try using `copied_df.drop_duplicates(keep='last')` instead â€” what changes?\n",
        "3. Explore whether duplicate rows share the same ID or just values across all columns and comment on your observation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyFVNN7fTtWq"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJNfob8qeGi"
      },
      "source": [
        "ðŸ”§ Add comment here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrGThmZxTsdG"
      },
      "source": [
        "## Part 5: Identify and Remove Obvious Outliers\n",
        "\n",
        "Outliers are values that fall far outside the normal range. They can come from data entry mistakes or rare cases.\n",
        "\n",
        "- Use summary statistics or visual tools (like boxplots) to find them.\n",
        "- Look for clearly unrealistic values â€” e.g., negative prices or extremely high data usage.\n",
        "- Decide how to handle them:\n",
        "  - Remove if theyâ€™re errors.\n",
        "  - Keep if theyâ€™re valid but rare â€” or cap them if needed.\n",
        "\n",
        "Outliers can distort averages, stretch visualizations, and mislead models, so itâ€™s important to address them carefully.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQkgPvH-TyV-"
      },
      "outputs": [],
      "source": [
        "# Remove negative or nonsensical values using business rules\n",
        "\n",
        "# Example: remove rows where 'handset_price' is negative\n",
        "df = df[df['handset_price'] >= 0]\n",
        "\n",
        "# Example: remove rows with unusually long call durations\n",
        "df = df[df['average_call_duration'] < 1000]\n",
        "\n",
        "# Example: remove rows with extremely high text message counts\n",
        "df = df[df['text_message_count'] < 1000]\n",
        "\n",
        "# View shape after outlier filtering\n",
        "print(\"Shape after removing obvious outliers:\", df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs44Te_xT1x0"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€“ Part 5\n",
        "\n",
        "1. Use `df.describe()` to look for columns with extreme minimum or maximum values.\n",
        "2. Set a threshold for what you think is \"too high\" or \"too low\" for:\n",
        "  - `data_mb_used`\n",
        "  - `over_15mins_calls_per_month`\n",
        "  - `income`\n",
        "3. Remove those outliers using boolean filtering like `df = df[df['column'] < threshold]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZht29q2U_qz"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ add code here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDo8Cbb5T5ve"
      },
      "source": [
        "## Part 6: Handle Outliers Using Quantiles\n",
        "\n",
        "Instead of removing outliers, we can limit their impact by capping extreme values â€” a method known as **Winsorizing**.\n",
        "\n",
        "### How to Do It:\n",
        "- Use `.quantile()` to identify the 1st and 99th percentiles (or other thresholds).\n",
        "- Use `.clip()` to cap values within that range.\n",
        "\n",
        "This keeps your dataset intact while reducing the influence of extreme values on your analysis or model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MsTpfh1T-MA"
      },
      "outputs": [],
      "source": [
        "# Calculate 1st and 99th percentiles for income\n",
        "income_min, income_max = df['income'].quantile([0.01, 0.99])\n",
        "\n",
        "# Use .loc to avoid SettingWithCopyWarning and ensure assignment modifies the original DataFrame\n",
        "df.loc[:, 'income'] = df['income'].clip(lower=income_min, upper=income_max)\n",
        "\n",
        "# Clip 'data_mb_used' to within 1st and 99th percentiles\n",
        "usage_min, usage_max = df['data_mb_used'].quantile([0.01, 0.99])\n",
        "df.loc[:, 'data_mb_used'] = df['data_mb_used'].clip(lower=usage_min, upper=usage_max)\n",
        "\n",
        "# Clip 'average_call_duration' to reduce the effect of extreme outliers\n",
        "call_min, call_max = df['average_call_duration'].quantile([0.01, 0.99])\n",
        "df.loc[:, 'average_call_duration'] = df['average_call_duration'].clip(lower=call_min, upper=call_max)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl2KH2laUPhJ"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€“ Part 6\n",
        "\n",
        "1. Use `.quantile([0.01, 0.99])` to find the range for:\n",
        "  - `text_message_count`\n",
        "  - `over_15mins_calls_per_month`\n",
        "2. Apply `.clip(lower=..., upper=...)` to reduce the impact of those outliers\n",
        "3. Compare the `.describe()` output before and after clipping and comment on what you observe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zddKz_siUTXm"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwiYJnFnrNLq"
      },
      "source": [
        "ðŸ”§ Add comment here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpSGvaBmT_9Y"
      },
      "source": [
        "## ðŸ”§ Part 7: Reflection (100 words or less per question)\n",
        "\n",
        "1. Which step fixed the most issues in the dataset?\n",
        "2. What surprised you about the structure or values?\n",
        "3. Do you feel this data is now ready for transformation in Lab 7?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srnE_g7zULEm"
      },
      "source": [
        "\n",
        "---\n",
        "ðŸ”§ **Add comment here:**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Your Notebook to Submit in Canvas\n",
        "- Use the instructions from Lab 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to html \"lab_06_LastnameFirstname.ipynb\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
