{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HKD7zytlC8T"
      },
      "source": [
        "> ### Note on Labs and Assignments:\n",
        ">\n",
        "> üîß Look for the **wrench emoji** üîß ‚Äî it highlights where you're expected to take action!\n",
        ">\n",
        "> These sections are graded and are not optional.\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wILWVHB_hdS9"
      },
      "source": [
        "# IS 4487 Lab 7: Data Transformation\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Load and preview the cleaned Megatelco dataset  \n",
        "- Engineer new columns from existing data  \n",
        "- Simplify or group variable values  \n",
        "- Use `.map()`, `.apply()`, and `pd.cut()` for transformations  \n",
        "- Try your own transformation logic  \n",
        "\n",
        "This lab continues from **Lab 6**, where we cleaned the Megatelco dataset.  \n",
        "\n",
        "Now, we will create new, more useful features for modeling and exploration.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Labs/lab_07_data_transformation.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "If you're new to Colab: [Colab FAQ](https://research.google.com/colaboratory/faq.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sL7v5VBhn0W"
      },
      "source": [
        "## Megatelco Data Dictionary\n",
        "\n",
        " DEMOGRAPHIC VARIABLES:\n",
        " - College - has the customer attended some college (one, zero)\n",
        " - Income - annual income of customer\n",
        " - House - estimated price of the customer's home (if applicable)\n",
        "\n",
        " USAGE VARIABLES:\n",
        " - Data Overage Mb - Average number of megabytes that the customer used in excess of the plan limit (over last 12 months)\n",
        " - Data Leftover Mb - Average number of megabytes that the customer use was below the plan limit (over last 12 months)\n",
        " - Data Mb Used - Average number of megabytes used per month (over last 12 months)\n",
        " - Text Message Count - Average number of texts per month (over last 12 months)\n",
        " - Over 15 Minute Calls Per Month - Average number of calls over 15 minutes in duration per month (over last 12 months)\n",
        " - Average Call Duration- Average call duration (over last 12 months)\n",
        "\n",
        "PHONE VARIABLES:\n",
        " - Operating System - Current operating system of phone\n",
        " - Handset Price - Retail price of the phone used by the customer\n",
        "\n",
        "ATTITUDINAL VARIABLES:\n",
        " - Reported Satisfaction - Survey response to \"How satisfied are you with your current phone plan?\" (high, med, low)\n",
        " - Reported Usage Level - Survey response to \"How much do your use your phone?\" (high, med, low)\n",
        " - Considering Change of Plan - Survey response to \"Are you currently planning to change companies when your contract expires?\" (high, med, low)\n",
        "\n",
        "OTHER VARIABLES\n",
        " - Leave - Did this customer churn with the last contract expiration? (LEAVE, STAY)\n",
        " - ID - Customer identifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5EdJF_oiJDb"
      },
      "source": [
        "# Part 1: Data Cleaning steps from Lab 6\n",
        "\n",
        "In this part of the lab, we will load the cleaning steps previously done in lab 6\n",
        "\n",
        "- Load the Megatelco dataset\n",
        "- Clean column names\n",
        "- Fix data types\n",
        "- Handle missing values\n",
        "- Remove duplicate records\n",
        "- Review for outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm4Pnq-ViH38"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Stan-Pugsley/is_4487_base/812e9f15c357a5657a2795631fcaa9d9363cb417/DataSets/megatelco_leave_survey_data_cleaning_v2.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#check datatypes\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Standardize column names\n",
        " - Remove leading/trailing whitespace\n",
        " - Convert to lowercase\n",
        " - Replace spaces with underscores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMUjbd91XJSL"
      },
      "outputs": [],
      "source": [
        "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "# Show info about data types and non-null values\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert Datatypes\n",
        "\n",
        "These steps were used in Lab 6.  We will use them again to get a usable dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBB0_QZGXLwH"
      },
      "outputs": [],
      "source": [
        "# Check original data types\n",
        "print(\"Original dtypes:\\n\", df.dtypes)\n",
        "\n",
        "# Convert yes/no columns to binary categories\n",
        "df['considering_change_of_plan'] = df['considering_change_of_plan'].map({'yes': 1, 'no': 0}).astype('category')\n",
        "df['leave'] = df['leave'].map({'yes': 1, 'no': 0}).astype('category')  # newly added\n",
        "\n",
        "# Convert categorical text columns to 'category' dtype\n",
        "df['college'] = df['college'].astype('category')\n",
        "df['reported_satisfaction'] = df['reported_satisfaction'].astype('category')\n",
        "df['reported_usage_level'] = df['reported_usage_level'].astype('category')  # newly added\n",
        "df['operating_system'] = df['operating_system'].astype('category')\n",
        "\n",
        "# Convert object/text columns with limited possible values with an order to ordinal categorical columns\n",
        "df['reported_satisfaction'] = pd.Categorical(df['reported_satisfaction'], categories = ['Low', 'Medium', 'High'], ordered = True)\n",
        "df['reported_usage_level'] = pd.Categorical(df['reported_usage_level'], categories = ['Low', 'Medium', 'High'], ordered = True)\n",
        "\n",
        "# Convert binary columns ('yes'/'no', 'LEAVE'/'STAY') to binary categorical\n",
        "df['considering_change_of_plan'] = df['considering_change_of_plan'].astype('category')\n",
        "df['leave'] = df['leave'].astype('category')  \n",
        "\n",
        "# Check updated data types\n",
        "print(\"\\nUpdated dtypes:\\n\", df.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAwvOBrFrayG"
      },
      "source": [
        "## Part 2: Creating New Features\n",
        "\n",
        "A major part of data preparation is **feature engineering** ‚Äî creating new columns from raw data to capture useful patterns.\n",
        "\n",
        "In this section, we will try three common methods:\n",
        "\n",
        "1. `.map()` ‚Äî useful for simplifying categories (e.g., satisfaction levels)\n",
        "2. `.apply()` ‚Äî allows flexible custom logic (e.g., flagging high usage)\n",
        "3. `pd.cut()` or `pd.qcut()` ‚Äî groups numeric values into bins or quantiles\n",
        "\n",
        "These new features help models learn better and make reports easier to interpret.\n",
        "\n",
        "Things to think about:\n",
        "- Are any categories too specific or inconsistent?\n",
        "- Can you create groups or flags to highlight important traits?\n",
        "- Would a simplified version of a column help with modeling or visualization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_MED-8urfIZ"
      },
      "outputs": [],
      "source": [
        "# Create a total data usage variable (used + leftover)\n",
        "df['total_data_mb'] = df['data_mb_used'] + df['data_leftover_mb']\n",
        "\n",
        "# Create a ratio of overage to used data\n",
        "df['overage_ratio'] = df['data_overage_mb'] / (df['data_mb_used'] + 1)  # add 1 to avoid divide-by-zero\n",
        "\n",
        "# Create a binary flag for high texters (over 500 texts)\n",
        "df['high_texter'] = (df['text_message_count'] > 500).astype(int)\n",
        "\n",
        "# Preview new columns\n",
        "df[['total_data_mb', 'overage_ratio', 'high_texter']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eJGGZGNrnQs"
      },
      "source": [
        "### üîß Try It Yourself ‚Äì Part 2\n",
        "\n",
        "1. Create a variable called `call_volume` by multiplying `over_15mins_calls_per_month` by `average_call_duration`\n",
        "2. Create a binary flag `high_data_user` for users where `data_mb_used` is above the median\n",
        "3. Use `.head()` to check your new columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EShvw6Pgrm2o"
      },
      "outputs": [],
      "source": [
        "# üîß Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M6JxcBTrtiL"
      },
      "source": [
        "## Part 3: Binning Continuous Variables\n",
        "\n",
        "Binning is the process of grouping numeric variables into categories (e.g., \"low\", \"medium\", \"high\").\n",
        "\n",
        "### Why We Bin:\n",
        "- Helps reduce the impact of outliers\n",
        "- Allows us to use numeric values in models that prefer categories\n",
        "- Simplifies interpretation and visualization\n",
        "\n",
        "### Things to think about:\n",
        "- Would grouping values make patterns more visible?\n",
        "- Do we want equal-sized groups or logical cutoffs?\n",
        "- Is the variable skewed?\n",
        "\n",
        "**Tools:**  \n",
        "- `pd.qcut()` for quantile-based bins (equal frequency)  \n",
        "- `pd.cut()` for equal-width or custom bins\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lamWtt-ogHvO"
      },
      "outputs": [],
      "source": [
        "# Bin income into 3 groups (quantiles): Low, Medium, High\n",
        "df['income_group'] = pd.qcut(df['income'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "# Bin average call duration into quartiles (labels as integers)\n",
        "df['call_duration_group'] = pd.qcut(df['average_call_duration'], q=4, labels=False)\n",
        "\n",
        "# Preview new groupings\n",
        "df[['income', 'income_group', 'average_call_duration', 'call_duration_group']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhEjG6aKr3PT"
      },
      "source": [
        "### üîß Try It Yourself ‚Äì Part 3\n",
        "\n",
        "1. Use `pd.cut()` to group `data_mb_used` into 3 labeled bins: \"Light\", \"Moderate\", \"Heavy\"\n",
        "2. Use `pd.qcut()` on `text_message_count` to split into 4 equal-sized groups\n",
        "3. Print `.value_counts()` on each new column to see how values are distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qPmmk--gOlt"
      },
      "outputs": [],
      "source": [
        "# üîß Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6NoAafqgf9S"
      },
      "source": [
        "## Part 4: Scaling Numeric Variables\n",
        "\n",
        "Scaling transforms values to a common range (often 0‚Äì1), which helps many machine learning models perform better.\n",
        "\n",
        "### When to Scale:\n",
        "- When features have very different ranges (e.g., income vs. call duration)\n",
        "- When using distance-based models (e.g., KNN, SVM)\n",
        "- When comparing magnitudes across features\n",
        "\n",
        "### Common Methods:\n",
        "- `MinMaxScaler`: scales to 0‚Äì1 range\n",
        "- `StandardScaler`: centers data around 0 with unit variance\n",
        "\n",
        "### Things to think about:\n",
        "- Are features on different scales?\n",
        "- Does my algorithm care about magnitude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxI-sMk5gli0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Choose columns to scale\n",
        "cols_to_scale = ['income', 'data_mb_used', 'average_call_duration']\n",
        "\n",
        "# Initialize and apply scaler\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = scaler.fit_transform(df[cols_to_scale])\n",
        "\n",
        "# Add scaled columns back to df\n",
        "df['income_scaled'] = df_scaled[:, 0]\n",
        "df['data_mb_used_scaled'] = df_scaled[:, 1]\n",
        "df['avg_call_dur_scaled'] = df_scaled[:, 2]\n",
        "\n",
        "# Preview\n",
        "df[['income_scaled', 'data_mb_used_scaled', 'avg_call_dur_scaled']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-12fAVuCgoK7"
      },
      "source": [
        "### üîß Try It Yourself ‚Äì ‚Äì Part 4\n",
        "\n",
        "1. Scale the `handset_price` and `over_15mins_calls_per_month` columns using `MinMaxScaler`\n",
        "2. Add the scaled values back to the dataframe using 2 new columns with suffix `_scaled`\n",
        "3. Use `.describe()` to compare original vs. scaled versions  \n",
        "\n",
        "### In Your Response: \n",
        "1. Make a comment on what you observe your comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHXzZhfDgtkL"
      },
      "outputs": [],
      "source": [
        "# üîß Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmJLOB8_sK72"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_I2LuDlgugI"
      },
      "source": [
        "## Part 5: Encoding Categorical Variables\n",
        "\n",
        "Most machine learning models can't handle string categories directly‚Äîso we convert them into numbers using **encoding**.\n",
        "\n",
        "### Types of Encoding:\n",
        "- **One-hot encoding**: creates a binary column for each category (preferred for nominal variables)\n",
        "- **Ordinal encoding**: assigns integers (use only for ordered categories)\n",
        "\n",
        "### Things to consider:\n",
        "- Is the variable nominal (e.g., OS type) or ordinal (e.g., satisfaction)?\n",
        "- How many unique categories are there?\n",
        "- Will one-hot encoding make the dataset too wide?\n",
        "\n",
        "**Tool:** `pd.get_dummies()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YBdj8fAg0nz"
      },
      "outputs": [],
      "source": [
        "# One-hot encode 'reported_usage_level'\n",
        "df_encoded = pd.get_dummies(df, columns=['reported_usage_level'], prefix='usage')\n",
        "\n",
        "# One-hot encode 'income_group'\n",
        "df_encoded = pd.get_dummies(df_encoded, columns=['income_group'], prefix='income')\n",
        "\n",
        "# Preview new columns\n",
        "df_encoded.filter(like='usage_').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzOTCzHag27N"
      },
      "source": [
        "### üîß Try It Yourself ‚Äì Part 5\n",
        "\n",
        "1. One-hot encode `reported_satisfaction` and `operating_system`\n",
        "2. Print `.shape` of your dataframe before and after to observe any big changes\n",
        "\n",
        "### In Your Response: \n",
        "1. How many new columns were added?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbdkRHnIg9J8"
      },
      "outputs": [],
      "source": [
        "# üîß Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1ABb7XNg-n4"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXhxOrGAhND3"
      },
      "source": [
        "# üîß Part 6: Reflection (100 words or less per question)\n",
        "\n",
        "1. Which transformation do you think had the biggest impact on preparing your data for modeling?\n",
        "2. Are there any features you created that you think will be especially useful for predicting churn?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgfLJTtmhM4I"
      },
      "source": [
        "### ‚úçÔ∏è Your Response: üîß\n",
        "1. \n",
        "2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Your Notebook to Submit in Canvas\n",
        "- Use the instructions from Lab 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to html \"lab_07_data_transformation.ipynb\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
