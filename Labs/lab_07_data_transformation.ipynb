{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HKD7zytlC8T"
      },
      "source": [
        "> # âš ï¸ **IMPORTANT: READ BEFORE STARTING THIS LAB**\n",
        ">\n",
        "> ### Throughout this lab, you will see **ðŸ”§ Try It Yourself** sections and a final ðŸ”§ **Reflection** section\n",
        ">\n",
        "> âœ… You are expected to:\n",
        "> - Complete each **\"ðŸ”§ Try It Yourselfâ€** section by writing and running your own code or answering the prompted questions in a markdown or python cell below the section.\n",
        "> - Answer the **Reflection** section at the end of the lab in your own words. This is your opportunity to summarize what you learned and connect the concepts.\n",
        "\n",
        ">\n",
        ">\n",
        "> ðŸ”§ Look for the **wrench emoji** ðŸ”§ â€” it highlights where you're expected to take action!\n",
        ">\n",
        "> ### These sections are **graded** and are **not optional**. Skipping them will impact your lab score.\n",
        ">\n",
        "> ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wILWVHB_hdS9"
      },
      "source": [
        "# IS 4487 Lab 7: Data Transformation\n",
        "\n",
        "## Outline\n",
        "\n",
        "- Load and preview the cleaned Megatelco dataset  \n",
        "- Engineer new columns from existing data  \n",
        "- Simplify or group variable values  \n",
        "- Use `.map()`, `.apply()`, and `pd.cut()` for transformations  \n",
        "- Try your own transformation logic  \n",
        "\n",
        "This lab continues from **Lab 6**, where we cleaned the Megatelco dataset.  \n",
        "\n",
        "Now, we will create new, more useful features for modeling and exploration.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Labs/lab_07_data_transformation.ipynb\" target=\"_parent\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "If you're new to Colab: [Colab FAQ](https://research.google.com/colaboratory/faq.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sL7v5VBhn0W"
      },
      "source": [
        "## Megatelco Data Dictionary\n",
        "\n",
        " DEMOGRAPHIC VARIABLES:\n",
        " - College - has the customer attended some college (one, zero)\n",
        " - Income - annual income of customer\n",
        " - House - estimated price of the customer's home (if applicable)\n",
        "\n",
        " USAGE VARIABLES:\n",
        " - Data Overage Mb - Average number of megabytes that the customer used in excess of the plan limit (over last 12 months)\n",
        " - Data Leftover Mb - Average number of megabytes that the customer use was below the plan limit (over last 12 months)\n",
        " - Data Mb Used - Average number of megabytes used per month (over last 12 months)\n",
        " - Text Message Count - Average number of texts per month (over last 12 months)\n",
        " - Over 15 Minute Calls Per Month - Average number of calls over 15 minutes in duration per month (over last 12 months)\n",
        " - Average Call Duration- Average call duration (over last 12 months)\n",
        "\n",
        "PHONE VARIABLES:\n",
        " - Operating System - Current operating system of phone\n",
        " - Handset Price - Retail price of the phone used by the customer\n",
        "\n",
        "ATTITUDINAL VARIABLES:\n",
        " - Reported Satisfaction - Survey response to \"How satisfied are you with your current phone plan?\" (high, med, low)\n",
        " - Reported Usage Level - Survey response to \"How much do your use your phone?\" (high, med, low)\n",
        " - Considering Change of Plan - Survey response to \"Are you currently planning to change companies when your contract expires?\" (high, med, low)\n",
        "\n",
        "OTHER VARIABLES\n",
        " - Leave - Did this customer churn with the last contract expiration? (LEAVE, STAY)\n",
        " - ID - Customer identifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5EdJF_oiJDb"
      },
      "source": [
        "# Part 1: Data Cleaning steps from Lab 6\n",
        "\n",
        "In this part of the lab, we will load the cleaning steps previously done in lab 6\n",
        "\n",
        "- Load the Megatelco dataset\n",
        "- Clean column names\n",
        "- Fix data types\n",
        "- Handle missing values\n",
        "- Remove duplicate records\n",
        "- Review for outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm4Pnq-ViH38"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Stan-Pugsley/is_4487_base/812e9f15c357a5657a2795631fcaa9d9363cb417/DataSets/megatelco_leave_survey_data_cleaning_v2.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMUjbd91XJSL"
      },
      "outputs": [],
      "source": [
        "# Standardize column names\n",
        "# - Remove leading/trailing whitespace\n",
        "# - Convert to lowercase\n",
        "# - Replace spaces with underscores\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "# Show info about data types and non-null values\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBB0_QZGXLwH"
      },
      "outputs": [],
      "source": [
        "# Check original data types\n",
        "print(\"Original dtypes:\\n\", df.dtypes)\n",
        "\n",
        "# Convert yes/no columns to binary categories\n",
        "df['considering_change_of_plan'] = df['considering_change_of_plan'].map({'yes': 1, 'no': 0}).astype('category')\n",
        "df['leave'] = df['leave'].map({'yes': 1, 'no': 0}).astype('category')  # newly added\n",
        "\n",
        "# Convert categorical text columns to 'category' dtype\n",
        "df['college'] = df['college'].astype('category')\n",
        "df['house'] = df['house'].astype('category')\n",
        "df['reported_satisfaction'] = df['reported_satisfaction'].astype('category')\n",
        "df['reported_usage_level'] = df['reported_usage_level'].astype('category')  # newly added\n",
        "df['operating_system'] = df['operating_system'].astype('category')\n",
        "\n",
        "# Convert numeric-looking columns from object to float\n",
        "df['income'] = pd.to_numeric(df['income'], errors='coerce')\n",
        "df['data_overage_mb'] = pd.to_numeric(df['data_overage_mb'], errors='coerce')\n",
        "df['data_leftover_mb'] = pd.to_numeric(df['data_leftover_mb'], errors='coerce')\n",
        "df['data_mb_used'] = pd.to_numeric(df['data_mb_used'], errors='coerce')\n",
        "df['text_message_count'] = pd.to_numeric(df['text_message_count'], errors='coerce')\n",
        "df['handset_price'] = pd.to_numeric(df['handset_price'], errors='coerce')  # newly added\n",
        "df['over_15mins_calls_per_month'] = pd.to_numeric(df['over_15mins_calls_per_month'], errors='coerce')\n",
        "df['average_call_duration'] = pd.to_numeric(df['average_call_duration'], errors='coerce')\n",
        "\n",
        "# Check updated data types\n",
        "print(\"\\nUpdated dtypes:\\n\", df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoV02_uweD-N"
      },
      "outputs": [],
      "source": [
        "# View missing value counts\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill 'handset_price' with median value\n",
        "df['handset_price'] = df['handset_price'].fillna(df['handset_price'].median())\n",
        "\n",
        "# Drop rows with missing income (assuming it's a small number of rows)\n",
        "df = df.dropna(subset=['income'])\n",
        "\n",
        "# Fill missing data_leftover_mb with 0 (if no leftover means truly zero)\n",
        "df['data_leftover_mb'] = df['data_leftover_mb'].fillna(0)\n",
        "\n",
        "# Fill missing call duration and data usage with their respective medians\n",
        "df['average_call_duration'] = df['average_call_duration'].fillna(df['average_call_duration'].median())\n",
        "df['data_mb_used'] = df['data_mb_used'].fillna(df['data_mb_used'].median())\n",
        "\n",
        "# Check updated missing values\n",
        "print(\"\\nMissing values after handling:\\n\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlvq5k7teI3O"
      },
      "outputs": [],
      "source": [
        "# Check for exact duplicates\n",
        "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
        "\n",
        "# Remove duplicate rows, keeping the first instance\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Confirm number of rows remaining\n",
        "print(f\"Remaining rows after removing duplicates: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRtGL8dieLad"
      },
      "outputs": [],
      "source": [
        "# Calculate 1st and 99th percentiles for income\n",
        "income_min, income_max = df['income'].quantile([0.01, 0.99])\n",
        "\n",
        "# Use .loc to avoid SettingWithCopyWarning and ensure assignment modifies the original DataFrame\n",
        "df.loc[:, 'income'] = df['income'].clip(lower=income_min, upper=income_max)\n",
        "\n",
        "# Clip 'data_mb_used' to within 1st and 99th percentiles\n",
        "usage_min, usage_max = df['data_mb_used'].quantile([0.01, 0.99])\n",
        "df.loc[:, 'data_mb_used'] = df['data_mb_used'].clip(lower=usage_min, upper=usage_max)\n",
        "\n",
        "# Clip 'average_call_duration' to reduce the effect of extreme outliers\n",
        "call_min, call_max = df['average_call_duration'].quantile([0.01, 0.99])\n",
        "df.loc[:, 'average_call_duration'] = df['average_call_duration'].clip(lower=call_min, upper=call_max)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAwvOBrFrayG"
      },
      "source": [
        "## Part 2: Creating New Features\n",
        "\n",
        "A major part of data preparation is **feature engineering** â€” creating new columns from raw data to capture useful patterns.\n",
        "\n",
        "In this section, we will try three common methods:\n",
        "\n",
        "1. `.map()` â€” useful for simplifying categories (e.g., satisfaction levels)\n",
        "2. `.apply()` â€” allows flexible custom logic (e.g., flagging high usage)\n",
        "3. `pd.cut()` or `pd.qcut()` â€” groups numeric values into bins or quantiles\n",
        "\n",
        "These new features help models learn better and make reports easier to interpret.\n",
        "\n",
        "Things to think about:\n",
        "- Are any categories too specific or inconsistent?\n",
        "- Can you create groups or flags to highlight important traits?\n",
        "- Would a simplified version of a column help with modeling or visualization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_MED-8urfIZ"
      },
      "outputs": [],
      "source": [
        "# Create a total data usage variable (used + leftover)\n",
        "df['total_data_mb'] = df['data_mb_used'] + df['data_leftover_mb']\n",
        "\n",
        "# Create a ratio of overage to used data\n",
        "df['overage_ratio'] = df['data_overage_mb'] / (df['data_mb_used'] + 1)  # add 1 to avoid divide-by-zero\n",
        "\n",
        "# Create a binary flag for high texters (over 500 texts)\n",
        "df['high_texter'] = (df['text_message_count'] > 500).astype(int)\n",
        "\n",
        "# Preview new columns\n",
        "df[['total_data_mb', 'overage_ratio', 'high_texter']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eJGGZGNrnQs"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€“ Part 2\n",
        "\n",
        "1. Create a variable called `call_volume` by multiplying `over_15mins_calls_per_month` by `average_call_duration`\n",
        "2. Create a binary flag `high_data_user` for users where `data_mb_used` is above the median\n",
        "3. Use `.head()` to check your new columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EShvw6Pgrm2o"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M6JxcBTrtiL"
      },
      "source": [
        "## Part 3: Binning Continous Variables\n",
        "\n",
        "Binning is the process of grouping numeric variables into categories (e.g., \"low\", \"medium\", \"high\").\n",
        "\n",
        "### Why We Bin:\n",
        "- Helps reduce the impact of outliers\n",
        "- Allows us to use numeric values in models that prefer categories\n",
        "- Simplifies interpretation and visualization\n",
        "\n",
        "### Things to think about:\n",
        "- Would grouping values make patterns more visible?\n",
        "- Do we want equal-sized groups or logical cutoffs?\n",
        "- Is the variable skewed?\n",
        "\n",
        "**Tools:**  \n",
        "- `pd.qcut()` for quantile-based bins (equal frequency)  \n",
        "- `pd.cut()` for equal-width or custom bins\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lamWtt-ogHvO"
      },
      "outputs": [],
      "source": [
        "# Bin income into 3 groups (quantiles): Low, Medium, High\n",
        "df['income_group'] = pd.qcut(df['income'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "# Bin average call duration into quartiles (labels as integers)\n",
        "df['call_duration_group'] = pd.qcut(df['average_call_duration'], q=4, labels=False)\n",
        "\n",
        "# Preview new groupings\n",
        "df[['income', 'income_group', 'average_call_duration', 'call_duration_group']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhEjG6aKr3PT"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€“ Part 3\n",
        "\n",
        "1. Use `pd.cut()` to group `data_mb_used` into 3 labeled bins: \"Light\", \"Moderate\", \"Heavy\"\n",
        "2. Use `pd.qcut()` on `text_message_count` to split into 4 equal-sized groups\n",
        "3. Print `.value_counts()` on each new column to see how values are distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qPmmk--gOlt"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6NoAafqgf9S"
      },
      "source": [
        "## Part 4: Scaling Numeric Variables\n",
        "\n",
        "Scaling transforms values to a common range (often 0â€“1), which helps many machine learning models perform better.\n",
        "\n",
        "### When to Scale:\n",
        "- When features have very different ranges (e.g., income vs. call duration)\n",
        "- When using distance-based models (e.g., KNN, SVM)\n",
        "- When comparing magnitudes across features\n",
        "\n",
        "### Common Methods:\n",
        "- `MinMaxScaler`: scales to 0â€“1 range\n",
        "- `StandardScaler`: centers data around 0 with unit variance\n",
        "\n",
        "### Things to think about:\n",
        "- Are features on different scales?\n",
        "- Does my algorithm care about magnitude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxI-sMk5gli0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Choose columns to scale\n",
        "cols_to_scale = ['income', 'data_mb_used', 'average_call_duration']\n",
        "\n",
        "# Initialize and apply scaler\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = scaler.fit_transform(df[cols_to_scale])\n",
        "\n",
        "# Add scaled columns back to df\n",
        "df['income_scaled'] = df_scaled[:, 0]\n",
        "df['data_mb_used_scaled'] = df_scaled[:, 1]\n",
        "df['avg_call_dur_scaled'] = df_scaled[:, 2]\n",
        "\n",
        "# Preview\n",
        "df[['income_scaled', 'data_mb_used_scaled', 'avg_call_dur_scaled']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-12fAVuCgoK7"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€“ â€“ Part 4\n",
        "\n",
        "1. Scale the `handset_price` and `over_15mins_calls_per_month` columns using `MinMaxScaler`\n",
        "2. Add the scaled values back to the dataframe with suffix `_scaled`\n",
        "3. Use `.describe()` to compare original vs. scaled versions and make a comment on what you observe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHXzZhfDgtkL"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmJLOB8_sK72"
      },
      "source": [
        "Add comment here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_I2LuDlgugI"
      },
      "source": [
        "## Part 5: Encoding Categorical Variables\n",
        "\n",
        "Most machine learning models can't handle string categories directlyâ€”so we convert them into numbers using **encoding**.\n",
        "\n",
        "### Types of Encoding:\n",
        "- **One-hot encoding**: creates a binary column for each category (preferred for nominal variables)\n",
        "- **Ordinal encoding**: assigns integers (use only for ordered categories)\n",
        "\n",
        "### Things to consider:\n",
        "- Is the variable nominal (e.g., OS type) or ordinal (e.g., satisfaction)?\n",
        "- How many unique categories are there?\n",
        "- Will one-hot encoding make the dataset too wide?\n",
        "\n",
        "**Tool:** `pd.get_dummies()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YBdj8fAg0nz"
      },
      "outputs": [],
      "source": [
        "# One-hot encode 'reported_usage_level'\n",
        "df_encoded = pd.get_dummies(df, columns=['reported_usage_level'], prefix='usage')\n",
        "\n",
        "# One-hot encode 'income_group'\n",
        "df_encoded = pd.get_dummies(df_encoded, columns=['income_group'], prefix='income')\n",
        "\n",
        "# Preview new columns\n",
        "df_encoded.filter(like='usage_').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzOTCzHag27N"
      },
      "source": [
        "### ðŸ”§ Try It Yourself â€“ Part 5\n",
        "\n",
        "1. One-hot encode `reported_satisfaction` and `operating_system`\n",
        "2. Print `.shape` of your dataframe before and after to observe any big changes\n",
        "3. How many new columns were added?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbdkRHnIg9J8"
      },
      "outputs": [],
      "source": [
        "# ðŸ”§ Add code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1ABb7XNg-n4"
      },
      "source": [
        "ðŸ”§ Add comment here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXhxOrGAhND3"
      },
      "source": [
        "# ðŸ”§ Part 6: Reflection (100 words or less per question)\n",
        "\n",
        "1. Which transformation do you think had the biggest impact on preparing your data for modeling?\n",
        "2. Are there any features you created that you think will be especially useful for predicting churn?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgfLJTtmhM4I"
      },
      "source": [
        "ðŸ”§ Add comment here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Your Notebook to Submit in Canvas\n",
        "- Use the instructions from Lab 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to html \"lab_07_LastnameFirstname.ipynb\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
