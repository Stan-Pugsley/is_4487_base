{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS4487 Week 14 - Practice Code\n",
    "\n",
    "In this notebook, you will performance image processing in two ways:\n",
    "1. Using powerful Python utilities for image to text processing\n",
    "2. Using an API to a call a web service to process the image (in this case using Gemini)\n",
    "\n",
    "## Business Application\n",
    "Image recognition is commonly be used to \n",
    "- Flag offensive content\n",
    "- Tag content for user search\n",
    "- Catalog and sort images\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Stan-Pugsley/is_4487_base/blob/main/Reading-PracticeScripts/week14_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Approach #1: Image recognition with Python\n",
    "\n",
    "Hugging Face is a collaborative platform and community for machine learning (ML) that provides open-source AI models, datasets, and tools, often called \"GitHub for Machine Learning\". It makes advanced AI, such as natural language processing (NLP) and computer vision, more accessible to developers by offering a central hub for sharing, discovering, and using pre-trained models and datasets with a few lines of code.  \n",
    "\n",
    "The Hugging Face ViTImageProcessor is a class within the Hugging Face Transformers library used to prepare images for the Vision Transformer (ViT) model. It handles essential preprocessing steps like resizing, normalizing, and formatting images to meet the specific input requirements of a ViT model. \n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "# Setup model and processor\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "processor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select an image to be classified\n",
    "There are three examples below:\n",
    "- Balloons\n",
    "- A stone sculpture\n",
    "- Abstract art\n",
    "\n",
    "Un-comment the one you would like to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_URL = \"https://target.scene7.com/is/image/Target/GUEST_1616af60-ab9a-44cb-93ce-2de272f1d252?wid=1200&hei=1200&qlt=80\"\n",
    "#IMAGE_URL = \"https://images.squarespace-cdn.com/content/v1/6150da9bc04b0a138b3c0600/1634528500503-V7KPRTKGCRB73IY6IKB9/Stone-Circle.jpg\"\n",
    "#IMAGE_URL = \"https://www.pacegallery.com/media/images/16_9-2.width-2000.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(requests.get(IMAGE_URL, stream=True).raw)\n",
    "\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "output_ids = model.generate(pixel_values, max_length=50)\n",
    "caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Caption:\", caption)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Approach #2: Image recognition with an API to an AI service\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, os\n",
    "from google import generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an API Key\n",
    "- Go to https://aistudio.google.com/api-keys\n",
    "- Click on the Get API key link on the bottom left corner\n",
    "- Copy the value into the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure your API key\n",
    "API_KEY = '##Paste your API key here##'\n",
    "genai.configure(api_key=API_KEY)\n",
    "print(\"Gemini API configured successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select an image to be classified\n",
    "There are three examples below:\n",
    "- Balloons\n",
    "- A stone sculpture\n",
    "- Abstract art\n",
    "\n",
    "Un-comment the one you would like to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_URL = \"https://target.scene7.com/is/image/Target/GUEST_1616af60-ab9a-44cb-93ce-2de272f1d252?wid=1200&hei=1200&qlt=80\"\n",
    "#IMAGE_URL = \"https://images.squarespace-cdn.com/content/v1/6150da9bc04b0a138b3c0600/1634528500503-V7KPRTKGCRB73IY6IKB9/Stone-Circle.jpg\"\n",
    "#IMAGE_URL = \"https://www.pacegallery.com/media/images/16_9-2.width-2000.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image\n",
    "img_bytes = requests.get(IMAGE_URL, timeout=10).content\n",
    "\n",
    "# call Gemini with the image + a classification prompt\n",
    "response = genai.GenerativeModel(model_name=\"gemini-2.5-flash\").generate_content(\n",
    "    contents=[{\"mime_type\": \"image/jpeg\",\"data\": img_bytes},\n",
    "        \"Identify the primary object in this image with a one-word label, and your confidence level between 0 and 1.\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('This is my label for your photo, with the conficence level: '+response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ideas\n",
    "- Add new images\n",
    "- Ask a true/false question like \"Does this image contain violence?\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
